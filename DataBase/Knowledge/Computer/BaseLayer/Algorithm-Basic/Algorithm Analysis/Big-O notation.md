#computer #algorithm
# Introduction
Big-O notation is a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity.
In computer science, big-O notation is used to classify algorithms
according to how their run time or space requirement grow as the order of approximation. 
f(N) is O(g(N)) if for some C and N0 the following condition holds:
$$\forall N>N_{0}; f(N)<C g(N)$$
This means that f grows at most as fast as Cg does.
$f(N) = \Omega(g(N))$, if g(N) = O(f(N))
$f(N)=\Theta(g(N))$ , if g(N) = O(f(N)) and f(N) = O(g(N))
# References 
https://www.topcoder.com/thrive/articles/Computational%20Complexity%20part%20one